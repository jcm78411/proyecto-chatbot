import os
import json
import nltk
import keras
import pickle
import itertools
import flet as ft
import numpy as np
from nltk.tokenize import word_tokenize
from nltk.stem.lancaster import LancasterStemmer
from sentence_transformers import SentenceTransformer
import faiss
from transformers import T5Tokenizer, T5ForConditionalGeneration
import requests
import json
from dotenv import load_dotenv

########################################
########################################
"""VOZ CON TTSX3"""
########################################
########################################

import pyttsx3
import threading

# Inicializar engine de pyttsx3 (una sola instancia global)
engine = pyttsx3.init()

# Configuraci√≥n b√°sica
try:
    engine.setProperty("rate", 150)      # velocidad de voz
    engine.setProperty("volume", 1.0)    # volumen (0.0 a 1.0)
except Exception:
    pass

# Intentar seleccionar una voz en espa√±ol si est√° disponible
try:
    voices = engine.getProperty("voices")
    chosen = None
    for v in voices:
        name = (v.name or "").lower()
        vid = (v.id or "").lower()
        # buscar pistas de "spanish" o "es"
        if "spanish" in name or "spanish" in vid or "es_" in vid or "es-" in vid or "es" == vid:
            chosen = v
            break
    if chosen:
        engine.setProperty("voice", chosen.id)
except Exception:
    pass

# Funci√≥n interna que habla (bloqueante)
def _speak(text: str):
    try:
        engine.say(str(text))
        engine.runAndWait()
    except Exception:
        # proteger contra errores de TTS en tiempo de ejecuci√≥n
        pass

# Lanza la voz en un hilo para no bloquear la UI
def speak_async(text: str):
    threading.Thread(target=_speak, args=(text,), daemon=True).start()

# Permite detener la reproducci√≥n si es necesario
def stop_speaking():
    try:
        engine.stop()
    except Exception:
        pass

tokenizer = T5Tokenizer.from_pretrained("t5-small")
model_t5 = T5ForConditionalGeneration.from_pretrained("t5-small")

nltk.download('punkt_tab')
nltk.download("punkt")
stemmer = LancasterStemmer()

dir_path = os.path.dirname(os.path.realpath(__file__))
extended_data_path = os.path.join(
    dir_path, "storage", "data", "singleton_dataset_extended.json"
)

with open(extended_data_path, "r", encoding="utf-8") as f:
    singleton_data = json.load(f)

with open("storage/data/singleton_dataset_extended.json", "r", encoding="utf-8") as f:
    singleton_data = json.load(f)

intents = {}
for item in singleton_data:
    tag = item.get("implementation_type", "unknown")
    code = item["code"]
    example = f"Ejemplo de c√≥digo ({tag}):\n\n{code.strip()}"
    if tag not in intents:
        intents[tag] = {
            "tag": tag,
            "patterns": [
                f"¬øC√≥mo se implementa un singleton tipo {tag}?",
                f"¬øTienes una implementaci√≥n {tag}?",
                f"¬øMe puedes mostrar un singleton con el estilo {tag}?",
                f"¬øCu√°l es el c√≥digo de singleton versi√≥n {tag}?",
                f"¬øC√≥mo hago una clase singleton usando el m√©todo {tag}?",
                f"Dame un ejemplo de singleton con enfoque {tag}",
                f"Quiero un singleton tipo {tag}, ¬øpuedes ayudarme?",
                f"¬øHay alguna forma de implementar singleton como {tag}?",
                f"¬øPuedes escribirme una clase singleton tipo {tag}?",
                f"Expl√≠came un singleton con patr√≥n {tag}",
                f"¬øEn qu√© consiste una implementaci√≥n {tag} del patr√≥n singleton?",
                f"¬øTienes c√≥digo {tag} de singleton?",
                f"¬øPuedes darme una muestra del singleton {tag}?",
                f"¬øC√≥mo luce una clase singleton con el estilo {tag}?",
                f"¬øPuedes generar un ejemplo {tag} para el patr√≥n singleton?",
            ],
            "responses": [example],
        }
    else:
        intents[tag]["responses"].append(example)

intents_list = {"intents": list(intents.values())}

implementation_theory = {
    "classic": (
        "El patr√≥n Singleton cl√°sico crea una √∫nica instancia de una clase y la almacena en una variable est√°tica dentro de la propia clase. "
        "Se proporciona un m√©todo de acceso (normalmente llamado `getInstance()` o similar) que devuelve esta instancia. "
        "Este enfoque es simple y funciona bien en entornos de un solo hilo, pero **no es seguro en entornos multihilo**, ya que dos hilos podr√≠an crear instancias simult√°neamente. "
        "No incluye control sobre la inicializaci√≥n diferida ni medidas contra reflexi√≥n o serializaci√≥n."
    ),
    "lazy": (
        "El Singleton lazy (inicializaci√≥n diferida) retrasa la creaci√≥n de la instancia hasta que esta es solicitada por primera vez. "
        "Esto reduce el uso innecesario de recursos si la instancia nunca llega a utilizarse. "
        "Sin embargo, **no es seguro en entornos multihilo a menos que se agregue sincronizaci√≥n** expl√≠cita. "
        "Es adecuado cuando la instancia es costosa de construir o puede no ser necesaria en todos los casos de uso."
    ),
    "thread_safe": (
        "El Singleton thread-safe garantiza que solo un hilo pueda crear la instancia, utilizando mecanismos como `synchronized`, `Lock`, o sem√°foros. "
        "Esto evita condiciones de carrera, pero **puede generar cuellos de botella por la sobrecarga de sincronizaci√≥n** si se accede frecuentemente al m√©todo. "
        "Es una soluci√≥n correcta en aplicaciones concurrentes, pero puede no ser la m√°s eficiente."
    ),
    "double_checked": (
        "La doble verificaci√≥n mejora la eficiencia del thread-safe cl√°sico. Primero verifica si la instancia ya fue creada sin sincronizaci√≥n. "
        "Solo si no existe, se entra en una secci√≥n cr√≠tica sincronizada y se vuelve a verificar. "
        "Esto evita sincronizar cada llamada despu√©s de la primera. "
        "**Requiere declarar la instancia como `volatile`** en Java para evitar problemas con el orden de ejecuci√≥n en entornos multihilo."
    ),
    "enum": (
        "El patr√≥n Singleton con `enum` en Java es considerado el m√°s robusto y seguro. "
        "Permite al compilador garantizar que solo existe una instancia, incluso frente a ataques por reflexi√≥n, clonaci√≥n o deserializaci√≥n. "
        "Es muy conciso (`INSTANCE;`) y **recomendado por Joshua Bloch en Effective Java**. "
        "No permite lazy initialization, pero a cambio ofrece simplicidad y protecci√≥n avanzada."
    ),
    "bill_pugh": (
        "Utiliza una clase interna est√°tica (`static inner class`) que contiene la instancia singleton. "
        "La clase no se carga hasta que se llama al m√©todo `getInstance()`, lo que garantiza inicializaci√≥n diferida y seguridad en m√∫ltiples hilos. "
        "**No requiere sincronizaci√≥n manual**, ya que la JVM asegura la carga del `classloader` de manera segura. "
        "Es considerado uno de los enfoques m√°s elegantes y eficientes en Java moderno."
    ),
    "synchronized": (
        "En este patr√≥n, el m√©todo `getInstance()` est√° completamente sincronizado, lo que significa que solo un hilo puede ejecutarlo a la vez. "
        "Esto resuelve los problemas de concurrencia, pero **introduce una penalizaci√≥n de rendimiento**, ya que incluso cuando la instancia ya existe, se sigue sincronizando. "
        "Es f√°cil de implementar pero no ideal para escenarios con muchas llamadas a `getInstance()`."
    ),
    "reflection_safe": (
        "Previene ataques por reflexi√≥n que podr√≠an permitir la creaci√≥n de m√∫ltiples instancias. "
        "El constructor privado lanza una excepci√≥n si ya existe una instancia, validando una variable de control antes de permitir la construcci√≥n. "
        "**Importante en Java**, donde es posible acceder a constructores privados mediante APIs de reflexi√≥n. "
        "No es infalible, pero a√±ade una capa importante de seguridad a la implementaci√≥n Singleton."
    ),
    "eager": (
        "La instancia se crea en el momento de la carga de la clase, ya sea al declarar directamente el campo o mediante un bloque est√°tico. "
        "Esto **garantiza la disponibilidad inmediata y seguridad en multihilo**, pero puede generar uso innecesario de memoria si la instancia nunca se usa. "
        "Es √∫til cuando se sabe con certeza que la instancia ser√° requerida."
    ),
    "static_block": (
        "Similar al eager, pero permite envolver la creaci√≥n de la instancia en un bloque `static {}` para manejar posibles excepciones. "
        "Esto es √∫til cuando la instancia depende de operaciones que puedan fallar (por ejemplo, lectura de archivos de configuraci√≥n o acceso a recursos externos). "
        "Combina seguridad de carga temprana con manejo de errores."
    ),
    "volatile": (
        "Usa la palabra clave `volatile` para garantizar la visibilidad inmediata de la instancia entre hilos. "
        "Suele combinarse con la doble verificaci√≥n para lograr **eficiencia, seguridad y correcta propagaci√≥n del valor** en entornos multihilo. "
        "Sin `volatile`, un hilo podr√≠a ver una versi√≥n parcialmente construida del objeto debido a reordenamientos del compilador o CPU."
    ),
    "registry": (
        "Este patr√≥n extiende el Singleton tradicional permitiendo m√∫ltiples instancias √∫nicas, cada una asociada a una clave (nombre, tipo, contexto). "
        "Todas las instancias se almacenan en un `map` o `diccionario` central. "
        "Es √∫til en aplicaciones grandes donde se requiere m√°s de un singleton especializado. "
        "Permite controlar y desacoplar el acceso a diferentes instancias desde un √∫nico punto de gesti√≥n."
    ),
    "inner_static_class": (
        "Es una forma m√°s precisa de referirse al patr√≥n Bill Pugh. Utiliza una clase est√°tica interna para mantener la instancia singleton. "
        "Aprovecha la carga diferida del `classloader`, lo cual garantiza inicializaci√≥n perezosa y segura en m√∫ltiples hilos sin sincronizaci√≥n expl√≠cita. "
        "Ideal en Java, ya que combina eficiencia, simplicidad y robustez."
    ),
    "metaclass": (
        "En Python, una metaclase puede usarse para modificar el comportamiento de creaci√≥n de clases. "
        "Al sobreescribir el m√©todo `__call__`, se puede interceptar cada intento de instanciaci√≥n y retornar siempre la misma instancia. "
        "Permite aplicar Singleton de forma gen√©rica a m√∫ltiples clases, ideal en arquitecturas extensibles o frameworks personalizados."
    ),
    "module": (
        "En Python, los m√≥dulos ya son objetos singleton por naturaleza. Una vez importado, el m√≥dulo se almacena en `sys.modules` y se reutiliza en cada importaci√≥n posterior. "
        "Esto hace innecesario implementar un patr√≥n Singleton expl√≠cito en muchos casos, especialmente para recursos compartidos o servicios globales. "
        "Es una soluci√≥n muy simple y efectiva en scripts y proyectos peque√±os."
    ),
    "borg": (
        "El patr√≥n Borg o Monostate, propuesto por Alex Martelli, permite crear m√∫ltiples instancias de una clase, pero todas comparten el mismo estado. "
        "Esto se logra haciendo que todas las instancias compartan el mismo diccionario interno (`__dict__`), o una estructura compartida como `__shared_state`. "
        "Es una alternativa flexible al Singleton cuando se desea desacoplar la identidad del objeto del estado compartido."
    ),
    "unknown": (
        "Esta categor√≠a se reserva para implementaciones at√≠picas o que no encajan claramente en las categor√≠as conocidas. "
        "Puede incluir combinaciones h√≠bridas, enfoques dependientes de framework, o t√©cnicas a√∫n no clasificadas. "
        "Requiere an√°lisis manual para determinar su viabilidad y prop√≥sito real."
    ),
}

theory_dataset = []
for intent in intents_list["intents"]:
    tag = intent["tag"]
    content = implementation_theory.get(
        tag, f"No se encontr√≥ teor√≠a definida para el tipo {tag}."
    )
    theory_dataset.append({"type": tag, "content": content})

with open(
    os.path.join(dir_path, "data_bot", "data_bot-main", "theory_dataset.json"),
    "w",
    encoding="utf-8",
) as f:
    json.dump(theory_dataset, f, indent=2, ensure_ascii=False)

print("Archivo 'theory_dataset.json' generado correctamente ‚úÖ")

with open(
    os.path.join(dir_path, "data_bot", "data_bot-main", "theory_dataset.json"),
    "r",
    encoding="utf-8",
) as f:
    theory_data = json.load(f)

# Inicializar modelo de embeddings
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")

# Crear lista de textos y tipos
texts = [doc["content"] for doc in theory_data]
types = [doc["type"] for doc in theory_data]

# Crear embeddings
theory_embeddings = embedding_model.encode(texts, convert_to_numpy=True)

# Crear √≠ndice FAISS
embedding_dim = theory_embeddings.shape[1]
faiss_index = faiss.IndexFlatL2(embedding_dim)
faiss_index.add(theory_embeddings)  # type: ignore

with open(
    os.path.join(dir_path, "data_bot", "data_bot-main", "data.json"),
    "w",
    encoding="utf-8",
) as f:
    json.dump(intents_list, f, indent=2, ensure_ascii=False)

words, all_words, tags, aux, auxA, auxB, training, exit_data = (
    [],
    [],
    [],
    [],
    [],
    [],
    [],
    [],
)

try:
    if not os.path.exists("Entrenamiento"):
        os.makedirs("Entrenamiento")

    with open("Entrenamiento/brain.words.pickle", "rb") as pickle_Brain:
        all_words, tags, training, exit_data = pickle.load(pickle_Brain)
except:
    for intent in intents_list["intents"]:
        for pattern in intent["patterns"]:
            auxWords = word_tokenize(pattern)
            auxA.append(auxWords)
            auxB.append(auxWords)
            aux.append(intent["tag"])

    ignore_words = [
        "?",
        "¬ø",
        "!",
        ".",
        ",",
        ":",
        ";",
        "(",
        ")",
        "[",
        "]",
        "{",
        "}",
        "'",
        '"',
        "`",
        "~",
        "@",
        "#",
        "$",
        "%",
        "^",
        "&",
        "*",
        "-",
        "_",
        "+",
        "=",
    ]
    for w in auxB:
        words.append(w)

    words = sorted(set(list(itertools.chain.from_iterable(words))))
    tags = sorted(set(aux))
    all_words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]
    all_words = sorted(set(all_words))
    null_exit = [0 for _ in range(len(tags))]

    for i, document in enumerate(auxA):
        bucket = []
        auxWords = [stemmer.stem(w.lower()) for w in document if w not in ignore_words]
        for w in all_words:
            bucket.append(1 if w in auxWords else 0)
        exit_row = null_exit[:]
        exit_row[tags.index(aux[i])] = 1
        training.append(bucket)
        exit_data.append(exit_row)

    training = np.array(training)
    exit_data = np.array(exit_data)

    if not os.path.exists("EntrenamientoPickle"):
        os.makedirs("EntrenamientoPickle")

    with open("EntrenamientoPickle/brain.words.pickle", "wb") as pickle_Brain:
        pickle.dump([all_words, tags, training, exit_data], pickle_Brain)

# ============================
# Red neuronal con TensorFlow
# ============================

model_path = os.path.join(dir_path, "EntrenamientoPickle", "brain_model.h5")
if os.path.isfile(model_path):
    model = keras.models.load_model(model_path)
    print("=" * 40)
    print("Modelo cargado desde el disco üíΩ")
    print("=" * 40)
else:
    model = keras.Sequential(
        [
            keras.layers.Input(shape=(len(training[0]),)),
            keras.layers.Dense(100, activation="relu"),
            keras.layers.Dense(50, activation="relu"),
            keras.layers.Dropout(0.5),
            keras.layers.Dense(len(exit_data[0]), activation="softmax"),
        ]
    )

    model.compile(
        optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"]
    )

    # epoch=1700
    model.fit(training, exit_data, epochs=2000, batch_size=128, validation_split=0.1, verbose=1)  # type: ignore
    model.save(model_path)
    print("=" * 40)
    print("Modelo guardado en disco üíæ")
    print("=" * 40)
    print("=" * 40)


load_dotenv()

API_KEY = os.getenv("API_KEY")
if not API_KEY:
    raise RuntimeError("API_KEY no encontrada en .env")

API_URL = "https://openrouter.ai/api/v1/chat/completions"
HEADERS = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json",
    "HTTP-Referer": "https://tusitio.com",
    "X-Title": "Chat Flet Llama3",
}

def obtener_respuesta(texto):
    try:
        # Construcci√≥n del cuerpo del mensaje
        data = {
            "model": "meta-llama/llama-3.3-70b-instruct:free",
            "messages": [
                {"role": "system", "content": "Eres un asistente √∫til, experto en ingenieria de sistemas, que responde con claridad exclusivamente sobre patrones de dise√±o singleton en java"},
                {"role": "user", "content": texto}
            ],
            "max_tokens": 512,
            "temperature": 0.8
        }

        # Petici√≥n a la API de OpenRouter
        response = requests.post(
            url="https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json",
                "HTTP-Referer": "<YOUR_SITE_URL>",  # (Opcional)
                "X-Title": "<YOUR_SITE_NAME>",       # (Opcional)
            },
            data=json.dumps(data)
        )

        # Comprobaci√≥n de errores HTTP
        if response.status_code != 200:
            print(f"‚ö†Ô∏è Error HTTP {response.status_code}: {response.text}")
            return "Ocurri√≥ un error al consultar el modelo."

        # Procesar la respuesta JSON
        result = response.json()

        # Extraer el contenido del mensaje del modelo
        return result["choices"][0]["message"]["content"].strip()

    except Exception as e:
        import traceback

        print("‚ö†Ô∏è Error al consultar el modelo:")
        traceback.print_exc()
        return "Lo siento, ocurri√≥ un error al procesar tu solicitud. Int√©ntalo de nuevo."


def generar_respuesta_api(pregunta, contexto):
    prompt = f"Pregunta: {pregunta}\n\nContexto:\n{contexto}\n\nRespuesta:"
    return obtener_respuesta(prompt)

def clasificar_pregunta(pregunta):
    pregunta = pregunta.lower()
    if any(
        p in pregunta for p in ["c√≥digo", "ejemplo", "implementaci√≥n", "mostrar", "ver"]
    ):
        return "codigo"
    elif any(
        p in pregunta for p in ["qu√©", "qu√© es", "definici√≥n", "significa", "consiste, hola"]
    ):
        return "teoria"
    elif "tipos de singleton" in pregunta:
        return "tipos"
    else:
        return "mixta"


def chat_rag(pregunta_usuario):
    tipo_pregunta = clasificar_pregunta(pregunta_usuario)
    pregunta = pregunta_usuario.strip()

    # Embedding y b√∫squeda sem√°ntica
    query_embedding = embedding_model.encode([pregunta])[0]
    D, I = faiss_index.search(np.array([query_embedding]), k=1) # type: ignore

    if I[0][0] >= len(theory_data):
        tipo = "unknown"
    else:
        tipo = theory_data[I[0][0]]["type"]

    teoria = next((d["content"] for d in theory_data if d["type"] == tipo), "")
    ejemplo_codigo = next(
        (
            item["code"]
            for item in singleton_data
            if "implementation_type" in item and item["implementation_type"] == tipo
        ),
        "",
    )

    if tipo_pregunta == "teoria":
        contexto = teoria
    elif tipo_pregunta == "codigo":
        contexto = ejemplo_codigo
    elif tipo_pregunta == "tipos":
        tipos_theoria = set(d["type"] for d in theory_data if d["type"] != "unknown")
        tipos_codigo = set(
            d["implementation_type"] for d in singleton_data if "implementation_type" in d
        )

        tipos_disponibles = sorted(tipos_theoria.union(tipos_codigo))
        return (
            "Los tipos de implementaci√≥n del patr√≥n Singleton que conozco son:\n- "
            + "\n- ".join(tipos_disponibles)
        )

    else:
        contexto = f"{teoria}\n\nEjemplo:\n{ejemplo_codigo}"

    return generar_respuesta_api(pregunta, contexto)


# ====================
# Funci√≥n de chatbot
# ====================

def main(page: ft.Page):

    win_width = 1366
    win_height = 768

    screen_width = 1366
    screen_height = 768

    page.window_left = (screen_width - win_width) // 2  # type: ignore
    page.window_top = (screen_height - win_height) // 2  # type: ignore

    page.window_width = win_width  # type: ignore
    page.window_height = win_height  # type: ignore
    page.window_resizable = True  # type: ignore

    page.title = "Chat con IA"
    page.horizontal_alignment = ft.CrossAxisAlignment.CENTER
    page.vertical_alignment = ft.MainAxisAlignment.CENTER

    chat_display = ft.Column(scroll="always", expand=True)  # type: ignore
    user_input = ft.TextField(label="Mensaje", expand=True, autofocus=True)
    send_btn = ft.ElevatedButton("Enviar", icon=ft.Icons.SEND)
    clear_btn = ft.ElevatedButton("Limpiar chat", icon=ft.Icons.DELETE)

    espera_label = ft.Text("ü§ñ Pensando...", visible=False)
    spinner = ft.ProgressRing(visible=False)

    def send_message(e):
        text = user_input.value.strip()  # type: ignore
        if not text:
            return

        chat_display.controls.append(
            ft.Row(
                [
                    ft.Container(
                        ft.Text(f"üßë‚Äçüíª Usuario: {text}"),
                        padding=10,
                        bgcolor=ft.Colors.BLUE,
                        border_radius=10,
                        alignment=ft.Alignment(1, 0),
                    )
                ],
                alignment=ft.MainAxisAlignment.END,
            )
        )
        user_input.value = ""
        user_input.focus()
        user_input.update()
        page.update()

        espera_label.visible = True
        spinner.visible = True
        espera_label.update()
        spinner.update()

        respuesta = chat_rag(text)
        speak_async(respuesta)

        espera_label.visible = False
        spinner.visible = False
        espera_label.update()
        spinner.update()
        chat_display.controls.append(
            ft.Row(
                [
                    ft.Container(
                        ft.Text(
                            f"ü§ñ IA:\n{respuesta}",
                            size=14,
                            font_family="Courier New",
                            no_wrap=False,
                            expand=True,
                        ),
                        padding=10,
                        bgcolor=ft.Colors.GREEN,
                        border_radius=10,
                        alignment=ft.Alignment(1, 0),
                        width=700,
                    )
                ],
                alignment=ft.MainAxisAlignment.START,
            )
        )

        page.update()

    def clear_chat(e):
        chat_display.controls.clear()
        page.update()

    send_btn.on_click = send_message
    clear_btn.on_click = clear_chat
    user_input.on_submit = send_message

    page.add(
        ft.Column(
            [
                ft.Text("ü§ñ Bienvenido al Chat IA", size=22, weight="bold", text_align="center"),  # type: ignore
                espera_label,
                spinner,
                ft.Container(
                    chat_display,
                    height=500,
                    bgcolor=ft.Colors.GREY,
                    border_radius=10,
                    padding=ft.Padding(left=50, right=50, top=10, bottom=10),
                    width=1365,
                    margin=ft.Margin(top=30, bottom=20, left=50, right=50),
                ),
                ft.Row(
                    [user_input, ft.Column([send_btn, clear_btn])],
                    alignment=ft.MainAxisAlignment.CENTER,
                ),
            ],
            horizontal_alignment=ft.CrossAxisAlignment.CENTER,
        )
    )


if __name__ == "__main__":
    ft.app(target=main)
